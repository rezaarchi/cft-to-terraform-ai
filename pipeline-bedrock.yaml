AWSTemplateFormatVersion: '2010-09-09'
Description: 'AI-Powered CI/CD Pipeline for CloudFormation to Terraform Conversion using AWS Bedrock Nova Pro'

Parameters:
  RepositoryName:
    Type: String
    Default: cft-to-terraform-ai-repo
    Description: Name of the CodeCommit repository
  
  TerraformStateBucket:
    Type: String
    Description: S3 bucket for Terraform state (must be globally unique)
  
  NotificationEmail:
    Type: String
    Description: Email for pipeline notifications
    Default: ''

Resources:
  # S3 Bucket for artifacts
  ArtifactBucket:
    Type: AWS::S3::Bucket
    Properties:
      BucketName: !Sub '${AWS::StackName}-artifacts-${AWS::AccountId}'
      VersioningConfiguration:
        Status: Enabled
      PublicAccessBlockConfiguration:
        BlockPublicAcls: true
        BlockPublicPolicy: true
        IgnorePublicAcls: true
        RestrictPublicBuckets: true
      BucketEncryption:
        ServerSideEncryptionConfiguration:
          - ServerSideEncryptionByDefault:
              SSEAlgorithm: AES256
      LifecycleConfiguration:
        Rules:
          - Id: DeleteOldArtifacts
            Status: Enabled
            ExpirationInDays: 30
            NoncurrentVersionExpirationInDays: 7

  # S3 Bucket for Terraform state
  TerraformStateBucketResource:
    Type: AWS::S3::Bucket
    Properties:
      BucketName: !Ref TerraformStateBucket
      VersioningConfiguration:
        Status: Enabled
      PublicAccessBlockConfiguration:
        BlockPublicAcls: true
        BlockPublicPolicy: true
        IgnorePublicAcls: true
        RestrictPublicBuckets: true
      BucketEncryption:
        ServerSideEncryptionConfiguration:
          - ServerSideEncryptionByDefault:
              SSEAlgorithm: AES256

  # SNS Topic for notifications
  PipelineNotificationTopic:
    Type: AWS::SNS::Topic
    Properties:
      TopicName: !Sub '${AWS::StackName}-notifications'
      DisplayName: AI-Powered CFT to Terraform Pipeline Notifications
      Subscription:
        - !If
          - HasNotificationEmail
          - Endpoint: !Ref NotificationEmail
            Protocol: email
          - !Ref AWS::NoValue

  # CodeCommit Repository
  SourceRepository:
    Type: AWS::CodeCommit::Repository
    Properties:
      RepositoryName: !Ref RepositoryName
      RepositoryDescription: Repository for CloudFormation templates - AI-powered conversion to Terraform
      Tags:
        - Key: Project
          Value: CFT-to-Terraform-AI
        - Key: ManagedBy
          Value: CloudFormation

  # CodeBuild IAM Role with Bedrock permissions
  CodeBuildServiceRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: codebuild.amazonaws.com
            Action: sts:AssumeRole
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/PowerUserAccess
      Policies:
        - PolicyName: CodeBuildBasePolicy
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - iam:*
                Resource: '*'
              - Effect: Allow
                Action:
                  - logs:CreateLogGroup
                  - logs:CreateLogStream
                  - logs:PutLogEvents
                Resource: '*'
              - Effect: Allow
                Action:
                  - s3:GetObject
                  - s3:PutObject
                  - s3:GetObjectVersion
                  - s3:ListBucket
                Resource:
                  - !GetAtt ArtifactBucket.Arn
                  - !Sub '${ArtifactBucket.Arn}/*'
                  - !GetAtt TerraformStateBucketResource.Arn
                  - !Sub '${TerraformStateBucketResource.Arn}/*'
              - Effect: Allow
                Action:
                  - cloudformation:ValidateTemplate
                  - cloudformation:DescribeStacks
                Resource: '*'
              - Effect: Allow
                Action:
                  - sns:Publish
                Resource: !Ref PipelineNotificationTopic
        - PolicyName: BedrockAccessPolicy
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - bedrock:InvokeModel
                  - bedrock:InvokeModelWithResponseStream
                  - bedrock:ListFoundationModels
                  - bedrock:GetFoundationModel
                Resource: 
                  - !Sub 'arn:aws:bedrock:${AWS::Region}::foundation-model/us.amazon.nova-pro-v1:0'
                  - !Sub 'arn:aws:bedrock:${AWS::Region}::foundation-model/*'

  # CodeBuild Project - AI-Powered Conversion
  AIConvertProject:
    Type: AWS::CodeBuild::Project
    Properties:
      Name: !Sub '${AWS::StackName}-ai-convert'
      Description: AI-powered CloudFormation to Terraform conversion using Bedrock Nova Pro
      ServiceRole: !GetAtt CodeBuildServiceRole.Arn
      Artifacts:
        Type: CODEPIPELINE
      Environment:
        Type: LINUX_CONTAINER
        ComputeType: BUILD_GENERAL1_LARGE
        Image: aws/codebuild/standard:7.0
        EnvironmentVariables:
          - Name: ARTIFACT_BUCKET
            Value: !Ref ArtifactBucket
          - Name: AWS_REGION
            Value: !Ref AWS::Region
          - Name: BEDROCK_MODEL_ID
            Value: us.amazon.nova-pro-v1:0
      Source:
        Type: CODEPIPELINE
        BuildSpec: |
          version: 0.2
          phases:
            install:
              runtime-versions:
                python: 3.13
              commands:
                - echo "Installing dependencies..."
                - pip install --upgrade pip
                - pip install boto3 pyyaml
                - echo "Installing Terraform..."
                - wget -q https://releases.hashicorp.com/terraform/1.13.3/terraform_1.13.3_linux_amd64.zip
                - unzip -q terraform_1.13.3_linux_amd64.zip
                - mv terraform /usr/local/bin/
                - terraform --version
            pre_build:
              commands:
                - echo "Pre-build checks..."
                - echo "Patching bedrock-ai-converter.py to handle CloudFormation YAML tags..."
                - |
                  cat > yaml_patch.py << 'EOFPATCH'
                  import sys
                  
                  # Read the original file
                  with open('bedrock-ai-converter.py', 'r') as f:
                      content = f.read()
                  
                  # Check if already patched
                  if 'yaml.SafeLoader.add_constructor' in content:
                      print("Already patched, skipping...")
                      sys.exit(0)
                  
                  # Add YAML constructors after imports
                  patch = """
                  # Add CloudFormation intrinsic function constructors for YAML parsing
                  yaml.SafeLoader.add_constructor('!Ref', lambda loader, node: {'Ref': loader.construct_scalar(node)})
                  yaml.SafeLoader.add_constructor('!GetAtt', lambda loader, node: {'Fn::GetAtt': loader.construct_scalar(node).split('.')})
                  yaml.SafeLoader.add_constructor('!Sub', lambda loader, node: {'Fn::Sub': loader.construct_scalar(node)})
                  yaml.SafeLoader.add_constructor('!Join', lambda loader, node: {'Fn::Join': loader.construct_sequence(node)})
                  yaml.SafeLoader.add_constructor('!Select', lambda loader, node: {'Fn::Select': loader.construct_sequence(node)})
                  yaml.SafeLoader.add_constructor('!Split', lambda loader, node: {'Fn::Split': loader.construct_sequence(node)})
                  yaml.SafeLoader.add_constructor('!GetAZs', lambda loader, node: {'Fn::GetAZs': loader.construct_scalar(node)})
                  yaml.SafeLoader.add_constructor('!Base64', lambda loader, node: {'Fn::Base64': loader.construct_scalar(node)})
                  yaml.SafeLoader.add_constructor('!Cidr', lambda loader, node: {'Fn::Cidr': loader.construct_sequence(node)})
                  yaml.SafeLoader.add_constructor('!ImportValue', lambda loader, node: {'Fn::ImportValue': loader.construct_scalar(node)})
                  yaml.SafeLoader.add_constructor('!FindInMap', lambda loader, node: {'Fn::FindInMap': loader.construct_sequence(node)})
                  yaml.SafeLoader.add_constructor('!If', lambda loader, node: {'Fn::If': loader.construct_sequence(node)})
                  yaml.SafeLoader.add_constructor('!Equals', lambda loader, node: {'Fn::Equals': loader.construct_sequence(node)})
                  yaml.SafeLoader.add_constructor('!Not', lambda loader, node: {'Fn::Not': loader.construct_sequence(node)})
                  yaml.SafeLoader.add_constructor('!And', lambda loader, node: {'Fn::And': loader.construct_sequence(node)})
                  yaml.SafeLoader.add_constructor('!Or', lambda loader, node: {'Fn::Or': loader.construct_sequence(node)})
                  """
                  
                  # Find the right place to insert (after imports, before class definition)
                  insert_pos = content.find('class CFTToTerraformConverter')
                  if insert_pos == -1:
                      insert_pos = content.find('class BedrockAIConverter')
                  
                  if insert_pos > 0:
                      new_content = content[:insert_pos] + patch + '\n' + content[insert_pos:]
                      with open('bedrock-ai-converter.py', 'w') as f:
                          f.write(new_content)
                      print("Patched successfully!")
                  else:
                      print("Could not find class definition, skipping patch")
                  EOFPATCH
                  
                  python3 yaml_patch.py
                - echo "Checking for bedrock-ai-converter.py..."
                - |
                  if [ ! -f "bedrock-ai-converter.py" ]; then
                    echo "ERROR: bedrock-ai-converter.py not found in repository!"
                    exit 1
                  fi
                - echo "Validating CloudFormation templates..."
                - |
                  for file in cloudformation/*.yaml cloudformation/*.yml cloudformation/*.json; do
                    if [ -f "$file" ]; then
                      echo "Validating $file"
                      aws cloudformation validate-template --template-body file://$file || exit 1
                    fi
                  done
            build:
              commands:
                - echo "Converting CloudFormation to Terraform using AWS Bedrock Nova Pro..."
                - mkdir -p terraform-output
                - echo "Listing CloudFormation files..."
                - ls -la cloudformation/
                - |
                  for cft_file in cloudformation/*.yaml cloudformation/*.yml cloudformation/*.json; do
                    if [ -f "$cft_file" ]; then
                      echo "=========================================="
                      echo "Processing $cft_file with AI..."
                      echo "=========================================="
                      python3 bedrock-ai-converter.py "$cft_file" terraform-output --region ${AWS_REGION} 2>&1 || {
                        echo "ERROR: Conversion failed for $cft_file"
                        echo "Checking if bedrock-ai-converter.py exists..."
                        ls -la bedrock-ai-converter.py
                        echo "Trying simple Python test..."
                        python3 --version
                        python3 -c "import boto3; print('boto3 imported successfully')"
                        exit 1
                      }
                    fi
                  done
                - echo "AI-powered conversion complete!"
                - echo "Listing output files..."
                - ls -la terraform-output/ || echo "terraform-output directory is empty or doesn't exist"
                - find terraform-output -type f || echo "No files found"
            post_build:
              commands:
                - echo "Post-build validation..."
                - cd terraform-output
                - |
                  cat > fix_security_groups.py << 'EOF'
                  import re
                  import glob

                  def fix_security_group_file(filepath):
                      with open(filepath, 'r') as f:
                          content = f.read()
                      
                      original = content
                      changes = 0
                      
                      # Fix security groups (existing logic converted to work with full content)
                      lines = content.split('\n')
                      fixed_lines = []
                      i = 0
                      
                      while i < len(lines):
                          line = lines[i]
                          
                          if re.search(r'^\s+source_security_group_id\s*=', line):
                              in_ingress_egress = False
                              brace_balance = 0
                              
                              for j in range(i - 1, -1, -1):
                                  prev_line = lines[j]
                                  brace_balance += prev_line.count('}') - prev_line.count('{')
                                  
                                  if re.search(r'\b(ingress|egress)\s*\{', prev_line) and brace_balance == 0:
                                      in_ingress_egress = True
                                      break
                                  
                                  if re.search(r'resource\s+"aws_security_group"', prev_line):
                                      break
                              
                              if not in_ingress_egress:
                                  print(f"  Line {i+1}: Removing misplaced source_security_group_id")
                                  changes += 1
                                  i += 1
                                  continue
                          
                          fixed_lines.append(line)
                          i += 1
                      
                      content = '\n'.join(fixed_lines)
                      
                      # Fix RDS attribute names
                      rds_fixes = 0
                      new_content = re.sub(r'\bpreferred_backup_window\s*=', 'backup_window =', content)
                      if new_content != content:
                          rds_fixes += content.count('preferred_backup_window')
                          content = new_content
                      
                      new_content = re.sub(r'\bpreferred_maintenance_window\s*=', 'maintenance_window =', content)
                      if new_content != content:
                          rds_fixes += content.count('preferred_maintenance_window')
                          content = new_content
                      
                      if rds_fixes > 0:
                          print(f"  Fixed {rds_fixes} RDS attribute name(s)")
                          changes += rds_fixes
                      
                      # Fix launch template structure
                      lt_match = re.search(r'launch_template_data\s*\{', content)
                      if lt_match:
                          print(f"  Removing invalid launch_template_data wrapper")
                          content = re.sub(r'\s*launch_template_data\s*\{\s*\n', '', content)
                          # Remove corresponding closing brace (find the matching one)
                          changes += 1
                      
                      if changes > 0:
                          with open(filepath, 'w') as f:
                              f.write(content)
                          print(f"  ✓ Fixed {changes} error(s) in {filepath}")
                          return True
                      else:
                          print(f"  ✓ No fixes needed for {filepath}")
                          return False

                  print("Scanning for Terraform errors...")
                  any_fixed = False
                  for tf_file in glob.glob("*.tf"):
                      print(f"\nChecking {tf_file}...")
                      if fix_security_group_file(tf_file):
                          any_fixed = True

                  if any_fixed:
                      print("\n✓ All Terraform syntax errors fixed!")
                  else:
                      print("\n✓ No errors found")
                  EOF
                - python3 fix_security_groups.py
                - echo "Showing fixed files for verification..."
                - |
                  for tf_file in *.tf; do
                    if [ -f "$tf_file" ]; then
                      echo "=== Checking $tf_file for remaining errors ==="
                      grep -n "source_security_group_id" "$tf_file" || echo "  No source_security_group_id found"
                    fi
                  done
                - |
                  for tf_file in *.tf; do
                    if [ -f "$tf_file" ] && [ "$tf_file" != "*_test.tf" ]; then
                      echo "Formatting $tf_file..."
                      terraform fmt "$tf_file" || true
                    fi
                  done
                - echo "Initializing Terraform for validation..."
                - terraform init -backend=false || echo "Init failed, skipping validation"
                - terraform validate || echo "Validation warnings present"
                - cd ..
          artifacts:
            files:
              - terraform-output/**/*
            name: ConvertedOutput

  # CodeBuild Project - Terraform Plan
  TerraformPlanProject:
    Type: AWS::CodeBuild::Project
    Properties:
      Name: !Sub '${AWS::StackName}-terraform-plan'
      Description: Generate Terraform execution plan
      ServiceRole: !GetAtt CodeBuildServiceRole.Arn
      Artifacts:
        Type: CODEPIPELINE
      Environment:
        Type: LINUX_CONTAINER
        ComputeType: BUILD_GENERAL1_MEDIUM
        Image: aws/codebuild/standard:7.0
        EnvironmentVariables:
          - Name: TF_STATE_BUCKET
            Value: !Ref TerraformStateBucket
          - Name: TF_STATE_KEY
            Value: terraform.tfstate
          - Name: AWS_REGION
            Value: !Ref AWS::Region
      Source:
        Type: CODEPIPELINE
        BuildSpec: |
          version: 0.2
          phases:
            install:
              runtime-versions:
                python: 3.13
              commands:
                - echo "Installing Terraform..."
                - wget -q https://releases.hashicorp.com/terraform/1.13.3/terraform_1.13.3_linux_amd64.zip
                - unzip -q terraform_1.13.3_linux_amd64.zip
                - mv terraform /usr/local/bin/
                - terraform --version
            pre_build:
              commands:
                - echo "Checking workspace files..."
                - ls -la
                - cd terraform-output
                - |
                  cat > fix_terraform_errors.py << 'EOF'
                  import re
                  import glob

                  def fix_terraform_file(filepath):
                      with open(filepath, 'r') as f:
                          content = f.read()
                      
                      original = content
                      changes = 0
                      
                      # Fix self-referential tags (VPC referencing itself)
                      if re.search(r'\$\{aws_vpc\.\w+\.id\}-vpc', content):
                          print(f"  Fixing VPC self-reference")
                          content = re.sub(r'\$\{aws_vpc\.(\w+)\.id\}-vpc', r'\1-vpc', content)
                          changes += 1

                      # Fix templatefile() usage
                      if 'templatefile(' in content:
                          print(f"  Removing templatefile() references")
                          content = re.sub(
                              r'user_data\s*=\s*base64encode\(templatefile\([^)]+\)\)',
                              '# user_data = base64encode("") # TODO: Add inline user data script',
                              content,
                              flags=re.DOTALL
                          )
                          changes += 1

                      # Fix RDS password issues - CONSOLIDATED VERSION
                      if 'aws_db_instance' in content:
                          print(f"  Checking RDS configuration")
                          
                          # Fix variable with empty default
                          if re.search(r'variable\s+"db_password".*?default\s*=\s*""', content, re.DOTALL):
                              print(f"  Fixing db_password variable with empty default")
                              content = re.sub(
                                  r'(variable\s+"db_password".*?default\s*=\s*)""\s*',
                                  r'\1"TempPassword123!"  # TODO: Set via tfvars or Secrets Manager\n  ',
                                  content,
                                  flags=re.DOTALL
                              )
                              changes += 1
                          
                          # Also check for empty password directly in resource
                          if re.search(r'\bpassword\s*=\s*""', content):
                              print(f"  Fixing empty RDS password attribute")
                              content = re.sub(r'password\s*=\s*""', 'password = "TempPassword123!"', content)
                              changes += 1
                          # Check for variable reference without default
                          elif re.search(r'password\s*=\s*var\.\w+', content) and 'variable ' not in content:
                              print(f"  Fixing RDS password variable reference")
                              content = re.sub(
                                  r'(password\s*=\s*)var\.\w+',
                                  r'\1"TempPassword123!"  # TODO: Use AWS Secrets Manager or tfvars',
                                  content
                              )
                              changes += 1

                      # Fix incorrect VPC gateway attachment resource name
                      if 'aws_vpc_gateway_attachment' in content:
                          print(f"  Fixing incorrect VPC gateway attachment resource name")
                          content = content.replace(
                              'resource "aws_vpc_gateway_attachment"',
                              'resource "aws_internet_gateway_attachment"'
                          )
                          content = content.replace(
                              'aws_vpc_gateway_attachment.',
                              'aws_internet_gateway_attachment.'
                          )
                          changes += 1
                      
                      # Fix any other self-references in tags
                      lines = content.split('\n')
                      fixed_lines = []
                      for i, line in enumerate(lines):
                          match = re.search(r'\$\{(aws_\w+)\.(\w+)\.(id|arn)\}', line)
                          if match:
                              resource_type = match.group(1)
                              resource_name = match.group(2)
                              for j in range(max(0, i-30), i):
                                  if f'resource "{resource_type}" "{resource_name}"' in lines[j]:
                                      print(f"  Line {i+1}: Fixing self-reference to {resource_name}")
                                      line = re.sub(r'\$\{[^}]+\}', resource_name, line)
                                      changes += 1
                                      break
                          fixed_lines.append(line)
                      
                      if changes > 0:
                          content = '\n'.join(fixed_lines)
                      
                      if content != original:
                          with open(filepath, 'w') as f:
                              f.write(content)
                          print(f"  ✓ Fixed {changes} error(s) in {filepath}")
                          return True
                      else:
                          print(f"  ✓ No fixes needed for {filepath}")
                          return False

                  print("Scanning for Terraform errors...")
                  any_fixed = False
                  for tf_file in glob.glob("*.tf"):
                      print(f"\nChecking {tf_file}...")
                      if fix_terraform_file(tf_file):
                          any_fixed = True

                  if any_fixed:
                      print("\n✓ All Terraform syntax errors fixed!")
                  else:
                      print("\n✓ No errors found")
                  EOF
                - python3 fix_terraform_errors.py
                - |
                  for tf_file in *.tf; do
                    [ -f "$tf_file" ] && terraform fmt "$tf_file" || true
                  done
                - |
                  if [ ! "$(find . -name '*.tf' -type f)" ]; then
                    echo "ERROR: No Terraform files found!"
                    exit 1
                  fi
                - echo "Initializing Terraform..."
                - terraform init -backend-config="bucket=${TF_STATE_BUCKET}" -backend-config="key=${TF_STATE_KEY}" -backend-config="region=${AWS_REGION}"
            build:
              commands:
                - echo "Running Terraform plan..."
                - terraform plan -out=tfplan
                - echo "Saving plan for review..."
                - terraform show -no-color tfplan > plan-output.txt
          artifacts:
            files:
              - terraform-output/**/*
            name: PlanOutput

  # CodeBuild Project - Terraform Apply
  TerraformApplyProject:
    Type: AWS::CodeBuild::Project
    Properties:
      Name: !Sub '${AWS::StackName}-terraform-apply'
      Description: Apply Terraform changes
      ServiceRole: !GetAtt CodeBuildServiceRole.Arn
      Artifacts:
        Type: CODEPIPELINE
      Environment:
        Type: LINUX_CONTAINER
        ComputeType: BUILD_GENERAL1_MEDIUM
        Image: aws/codebuild/standard:7.0
        EnvironmentVariables:
          - Name: TF_STATE_BUCKET
            Value: !Ref TerraformStateBucket
          - Name: TF_STATE_KEY
            Value: terraform.tfstate
          - Name: AWS_REGION
            Value: !Ref AWS::Region
          - Name: SNS_TOPIC_ARN
            Value: !Ref PipelineNotificationTopic
      Source:
        Type: CODEPIPELINE
        BuildSpec: |
          version: 0.2
          phases:
            install:
              runtime-versions:
                python: 3.13
              commands:
                - echo "Installing Terraform..."
                - wget https://releases.hashicorp.com/terraform/1.13.3/terraform_1.13.3_linux_amd64.zip
                - unzip terraform_1.13.3_linux_amd64.zip
                - mv terraform /usr/local/bin/
                - terraform --version
            pre_build:
              commands:
                - cd terraform-output
                - echo "Re-initializing Terraform..."
                - terraform init -backend-config="bucket=${TF_STATE_BUCKET}" -backend-config="key=${TF_STATE_KEY}" -backend-config="region=${AWS_REGION}"
            build:
              commands:
                - echo "Applying Terraform changes..."
                - terraform apply -auto-approve tfplan
                - echo "Capturing outputs..."
                - terraform output -json > terraform-outputs.json
            post_build:
              commands:
                - echo "Deployment complete!"
                - terraform show -no-color > deployment-state.txt || true
                - terraform output -json > terraform-outputs.json 2>/dev/null || echo '{}' > terraform-outputs.json
                - aws s3 cp terraform-outputs.json s3://${TF_STATE_BUCKET}/outputs/outputs-${CODEBUILD_BUILD_NUMBER}.json || true
                - aws s3 cp deployment-state.txt s3://${TF_STATE_BUCKET}/states/state-${CODEBUILD_BUILD_NUMBER}.txt || true
                - |
                  if [ ! -z "${SNS_TOPIC_ARN}" ]; then
                    aws sns publish --topic-arn ${SNS_TOPIC_ARN} \
                      --subject "Terraform Deployment Successful" \
                      --message "Build ${CODEBUILD_BUILD_NUMBER} deployed successfully. Check S3 for outputs."
                  fi
          artifacts:
            files:
              - terraform-output/terraform-outputs.json
              - terraform-output/deployment-state.txt
            name: TerraformApplyArtifacts
      TimeoutInMinutes: 30

  # CodePipeline IAM Role
  CodePipelineServiceRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: codepipeline.amazonaws.com
            Action: sts:AssumeRole
      Policies:
        - PolicyName: CodePipelinePolicy
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - s3:GetObject
                  - s3:PutObject
                  - s3:GetObjectVersion
                  - s3:GetBucketLocation
                  - s3:ListBucket
                Resource:
                  - !GetAtt ArtifactBucket.Arn
                  - !Sub '${ArtifactBucket.Arn}/*'
              - Effect: Allow
                Action:
                  - codecommit:GetBranch
                  - codecommit:GetCommit
                  - codecommit:UploadArchive
                  - codecommit:GetUploadArchiveStatus
                Resource: !GetAtt SourceRepository.Arn
              - Effect: Allow
                Action:
                  - codebuild:BatchGetBuilds
                  - codebuild:StartBuild
                Resource:
                  - !GetAtt AIConvertProject.Arn
                  - !GetAtt TerraformPlanProject.Arn
                  - !GetAtt TerraformApplyProject.Arn
              - Effect: Allow
                Action:
                  - sns:Publish
                Resource: !Ref PipelineNotificationTopic

  # CodePipeline
  Pipeline:
    Type: AWS::CodePipeline::Pipeline
    Properties:
      Name: !Sub '${AWS::StackName}-pipeline'
      RoleArn: !GetAtt CodePipelineServiceRole.Arn
      ArtifactStore:
        Type: S3
        Location: !Ref ArtifactBucket
      Stages:
        - Name: Source
          Actions:
            - Name: SourceAction
              ActionTypeId:
                Category: Source
                Owner: AWS
                Provider: CodeCommit
                Version: '1'
              Configuration:
                RepositoryName: !GetAtt SourceRepository.Name
                BranchName: main
                PollForSourceChanges: false
              OutputArtifacts:
                - Name: SourceOutput

        - Name: AI-Convert
          Actions:
            - Name: BedrockAIConversion
              ActionTypeId:
                Category: Build
                Owner: AWS
                Provider: CodeBuild
                Version: '1'
              Configuration:
                ProjectName: !Ref AIConvertProject
              InputArtifacts:
                - Name: SourceOutput
              OutputArtifacts:
                - Name: ConvertedOutput
              RunOrder: 1

        - Name: Terraform-Plan
          Actions:
            - Name: TerraformPlan
              ActionTypeId:
                Category: Build
                Owner: AWS
                Provider: CodeBuild
                Version: '1'
              Configuration:
                ProjectName: !Ref TerraformPlanProject
              InputArtifacts:
                - Name: ConvertedOutput
              OutputArtifacts:
                - Name: PlanOutput
              RunOrder: 1

        - Name: Manual-Approval
          Actions:
            - Name: ReviewAndApprove
              ActionTypeId:
                Category: Approval
                Owner: AWS
                Provider: Manual
                Version: '1'
              Configuration:
                NotificationArn: !Ref PipelineNotificationTopic
                CustomData: !Sub |
                  AI-powered conversion complete. Please review:
                  
                  1. Check conversion report in S3: s3://${ArtifactBucket}/conversion-reports/
                  2. Review Terraform plan in S3: s3://${TerraformStateBucket}/plans/
                  3. Verify all resources are correctly converted
                  4. Approve to deploy infrastructure
                  
                  Pipeline: ${AWS::StackName}
              RunOrder: 1

        - Name: Deploy
          Actions:
            - Name: TerraformApply
              ActionTypeId:
                Category: Build
                Owner: AWS
                Provider: CodeBuild
                Version: '1'
              Configuration:
                ProjectName: !Ref TerraformApplyProject
              InputArtifacts:
                - Name: PlanOutput
              RunOrder: 1

  # EventBridge Rule to trigger pipeline on commit
  PipelineTriggerRule:
    Type: AWS::Events::Rule
    Properties:
      Description: Trigger AI-powered pipeline on CodeCommit changes
      EventPattern:
        source:
          - aws.codecommit
        detail-type:
          - CodeCommit Repository State Change
        detail:
          event:
            - referenceCreated
            - referenceUpdated
          referenceName:
            - main
          repositoryName:
            - !GetAtt SourceRepository.Name
      State: ENABLED
      Targets:
        - Arn: !Sub 'arn:aws:codepipeline:${AWS::Region}:${AWS::AccountId}:${Pipeline}'
          RoleArn: !GetAtt EventBridgeRole.Arn
          Id: CodePipelineTarget

  # IAM Role for EventBridge
  EventBridgeRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service: events.amazonaws.com
            Action: sts:AssumeRole
      Policies:
        - PolicyName: StartPipelinePolicy
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action: codepipeline:StartPipelineExecution
                Resource: !Sub 'arn:aws:codepipeline:${AWS::Region}:${AWS::AccountId}:${Pipeline}'

  # CloudWatch Dashboard for monitoring
  PipelineDashboard:
    Type: AWS::CloudWatch::Dashboard
    Properties:
      DashboardName: !Sub '${AWS::StackName}-dashboard'
      DashboardBody: !Sub |
        {
          "widgets": [
            {
              "type": "metric",
              "properties": {
                "metrics": [
                  ["AWS/CodePipeline", "PipelineExecutionSuccess", {"stat": "Sum"}],
                  [".", "PipelineExecutionFailure", {"stat": "Sum"}]
                ],
                "period": 300,
                "stat": "Sum",
                "region": "${AWS::Region}",
                "title": "Pipeline Executions",
                "yAxis": {
                  "left": {
                    "min": 0
                  }
                }
              }
            },
            {
              "type": "metric",
              "properties": {
                "metrics": [
                  ["AWS/CodeBuild", "Duration", {"stat": "Average"}]
                ],
                "period": 300,
                "stat": "Average",
                "region": "${AWS::Region}",
                "title": "Build Duration",
                "yAxis": {
                  "left": {
                    "min": 0
                  }
                }
              }
            }
          ]
        }

Conditions:
  HasNotificationEmail: !Not [!Equals [!Ref NotificationEmail, '']]

Outputs:
  RepositoryCloneUrlHttp:
    Description: HTTP Clone URL for the CodeCommit repository
    Value: !GetAtt SourceRepository.CloneUrlHttp
    Export:
      Name: !Sub '${AWS::StackName}-repo-http-url'
  
  RepositoryCloneUrlSsh:
    Description: SSH Clone URL for the CodeCommit repository
    Value: !GetAtt SourceRepository.CloneUrlSsh
    Export:
      Name: !Sub '${AWS::StackName}-repo-ssh-url'
  
  PipelineUrl:
    Description: URL to the CodePipeline console
    Value: !Sub 'https://console.aws.amazon.com/codesuite/codepipeline/pipelines/${Pipeline}/view'
    Export:
      Name: !Sub '${AWS::StackName}-pipeline-url'
  
  ArtifactBucketName:
    Description: S3 bucket for pipeline artifacts
    Value: !Ref ArtifactBucket
    Export:
      Name: !Sub '${AWS::StackName}-artifact-bucket'
  
  TerraformStateBucketName:
    Description: S3 bucket for Terraform state
    Value: !Ref TerraformStateBucket
    Export:
      Name: !Sub '${AWS::StackName}-tfstate-bucket'
  
  DashboardUrl:
    Description: CloudWatch Dashboard URL
    Value: !Sub 'https://console.aws.amazon.com/cloudwatch/home?region=${AWS::Region}#dashboards:name=${AWS::StackName}-dashboard'
    Export:
      Name: !Sub '${AWS::StackName}-dashboard-url'
  
  BedrockModelId:
    Description: Bedrock model ID used for conversion
    Value: us.amazon.nova-pro-v1:0
    Export:
      Name: !Sub '${AWS::StackName}-bedrock-model'